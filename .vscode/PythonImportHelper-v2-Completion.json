[
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torchvision.models",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.models",
        "description": "torchvision.models",
        "detail": "torchvision.models",
        "documentation": {}
    },
    {
        "label": "GCM",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "aggregation_final",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "aggregation_init",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "Refine",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "ChannelAttention",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SpatialAttention",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "BasicConv2d",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel_visualization",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel",
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "isExtraImport": true,
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageEnhance",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageEnhance",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "torch.utils.data",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "torchvision.transforms",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "rasterio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "rasterio",
        "description": "rasterio",
        "detail": "rasterio",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "profile",
        "importPath": "thop",
        "description": "thop",
        "isExtraImport": true,
        "detail": "thop",
        "documentation": {}
    },
    {
        "label": "clever_format",
        "importPath": "thop",
        "description": "thop",
        "isExtraImport": true,
        "detail": "thop",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "tensorboardX",
        "description": "tensorboardX",
        "isExtraImport": true,
        "detail": "tensorboardX",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "data_loader",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "data_loader",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "data_loader",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "data_loader",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "data_loader",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "data_loader",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "data_loader",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "data_loader_tif",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "data_loader",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "isExtraImport": true,
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "HANet_v2",
        "importPath": "network.Net2",
        "description": "network.Net2",
        "isExtraImport": true,
        "detail": "network.Net2",
        "documentation": {}
    },
    {
        "label": "HANet_v3",
        "importPath": "network.Net2",
        "description": "network.Net2",
        "isExtraImport": true,
        "detail": "network.Net2",
        "documentation": {}
    },
    {
        "label": "HANet_v4",
        "importPath": "network.Net2",
        "description": "network.Net2",
        "isExtraImport": true,
        "detail": "network.Net2",
        "documentation": {}
    },
    {
        "label": "HANet_v2",
        "importPath": "network.Net2",
        "description": "network.Net2",
        "isExtraImport": true,
        "detail": "network.Net2",
        "documentation": {}
    },
    {
        "label": "HANet_v3",
        "importPath": "network.Net2",
        "description": "network.Net2",
        "isExtraImport": true,
        "detail": "network.Net2",
        "documentation": {}
    },
    {
        "label": "HANet_v4",
        "importPath": "network.Net2",
        "description": "network.Net2",
        "isExtraImport": true,
        "detail": "network.Net2",
        "documentation": {}
    },
    {
        "label": "HANet_v5",
        "importPath": "network.Net3",
        "description": "network.Net3",
        "isExtraImport": true,
        "detail": "network.Net3",
        "documentation": {}
    },
    {
        "label": "HANet_v6",
        "importPath": "network.Net3",
        "description": "network.Net3",
        "isExtraImport": true,
        "detail": "network.Net3",
        "documentation": {}
    },
    {
        "label": "HANet_v6_Ablation",
        "importPath": "network.Net3",
        "description": "network.Net3",
        "isExtraImport": true,
        "detail": "network.Net3",
        "documentation": {}
    },
    {
        "label": "HANet_v5",
        "importPath": "network.Net3",
        "description": "network.Net3",
        "isExtraImport": true,
        "detail": "network.Net3",
        "documentation": {}
    },
    {
        "label": "HANet_v6",
        "importPath": "network.Net3",
        "description": "network.Net3",
        "isExtraImport": true,
        "detail": "network.Net3",
        "documentation": {}
    },
    {
        "label": "HANet_v6_Ablation",
        "importPath": "network.Net3",
        "description": "network.Net3",
        "isExtraImport": true,
        "detail": "network.Net3",
        "documentation": {}
    },
    {
        "label": "HANModel3",
        "importPath": "network.CD_Model",
        "description": "network.CD_Model",
        "isExtraImport": true,
        "detail": "network.CD_Model",
        "documentation": {}
    },
    {
        "label": "HANModel3",
        "importPath": "network.CD_Model",
        "description": "network.CD_Model",
        "isExtraImport": true,
        "detail": "network.CD_Model",
        "documentation": {}
    },
    {
        "label": "Ablation_model",
        "importPath": "network",
        "description": "network",
        "isExtraImport": true,
        "detail": "network",
        "documentation": {}
    },
    {
        "label": "Ablation_model",
        "importPath": "network",
        "description": "network",
        "isExtraImport": true,
        "detail": "network",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "utils.visualization",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "replace_GCM",
        "kind": 6,
        "importPath": "network.Ablation_model",
        "description": "network.Ablation_model",
        "peekOfCode": "class replace_GCM(nn.Module):\n    def __init__(self, in_channel, out_channel):\n        super(replace_GCM, self).__init__()\n        self.relu = nn.ReLU(True)\n        # self.branch0 = nn.Sequential(\n        #     BasicConv2d(in_channel, out_channel, 1),\n        # )\n        # self.branch1 = nn.Sequential(\n        #     BasicConv2d(in_channel, out_channel, 1),\n        #     BasicConv2d(out_channel, out_channel, kernel_size=(1, 3), padding=(0, 1)),",
        "detail": "network.Ablation_model",
        "documentation": {}
    },
    {
        "label": "SemiModel_without_GCM_3_4_5",
        "kind": 6,
        "importPath": "network.Ablation_model",
        "description": "network.Ablation_model",
        "peekOfCode": "class SemiModel_without_GCM_3_4_5(nn.Module):\n    def __init__(self, channel=32):\n        super(SemiModel_without_GCM_3_4_5, self).__init__()\n        vgg16_bn = models.vgg16_bn(pretrained=True)\n        self.inc = vgg16_bn.features[:5]  # 64\n        self.down1 = vgg16_bn.features[5:12]  # 128\n        self.down2 = vgg16_bn.features[12:22]  # 256\n        self.down3 = vgg16_bn.features[22:32]  # 512\n        self.down4 = vgg16_bn.features[32:42]  # 512\n        self.rfb3 = replace_GCM(256, channel)",
        "detail": "network.Ablation_model",
        "documentation": {}
    },
    {
        "label": "SemiModel_without_GCM_1_2_3",
        "kind": 6,
        "importPath": "network.Ablation_model",
        "description": "network.Ablation_model",
        "peekOfCode": "class SemiModel_without_GCM_1_2_3(nn.Module):\n    def __init__(self, channel=32):\n        super(SemiModel_without_GCM_1_2_3, self).__init__()\n        vgg16_bn = models.vgg16_bn(pretrained=True)\n        self.inc = vgg16_bn.features[:5]  # 64\n        self.down1 = vgg16_bn.features[5:12]  # 128\n        self.down2 = vgg16_bn.features[12:22]  # 256\n        self.down3 = vgg16_bn.features[22:32]  # 512\n        self.down4 = vgg16_bn.features[32:42]  # 512\n        self.rfb3 = GCM(256, channel)",
        "detail": "network.Ablation_model",
        "documentation": {}
    },
    {
        "label": "SemiModel_without_all_GCM",
        "kind": 6,
        "importPath": "network.Ablation_model",
        "description": "network.Ablation_model",
        "peekOfCode": "class SemiModel_without_all_GCM(nn.Module):\n    def __init__(self, channel=32):\n        super(SemiModel_without_all_GCM, self).__init__()\n        vgg16_bn = models.vgg16_bn(pretrained=True)\n        self.inc = vgg16_bn.features[:5]  # 64\n        self.down1 = vgg16_bn.features[5:12]  # 128\n        self.down2 = vgg16_bn.features[12:22]  # 256\n        self.down3 = vgg16_bn.features[22:32]  # 512\n        self.down4 = vgg16_bn.features[32:42]  # 512\n        self.rfb3 = replace_GCM(256, channel)",
        "detail": "network.Ablation_model",
        "documentation": {}
    },
    {
        "label": "SemiModel_without_Refine",
        "kind": 6,
        "importPath": "network.Ablation_model",
        "description": "network.Ablation_model",
        "peekOfCode": "class SemiModel_without_Refine(nn.Module):\n    def __init__(self, channel=32):\n        super(SemiModel_without_Refine, self).__init__()\n        vgg16_bn = models.vgg16_bn(pretrained=True)\n        self.inc = vgg16_bn.features[:5]  # 64\n        self.down1 = vgg16_bn.features[5:12]  # 128\n        self.down2 = vgg16_bn.features[12:22]  # 256\n        self.down3 = vgg16_bn.features[22:32]  # 512\n        self.down4 = vgg16_bn.features[32:42]  # 512\n        self.rfb3 = GCM(256, channel)",
        "detail": "network.Ablation_model",
        "documentation": {}
    },
    {
        "label": "replace_aggregation_init",
        "kind": 6,
        "importPath": "network.Ablation_model",
        "description": "network.Ablation_model",
        "peekOfCode": "class replace_aggregation_init(nn.Module):\n    def __init__(self, channel):\n        super(replace_aggregation_init, self).__init__()\n        self.relu = nn.ReLU(True)\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        # self.conv_upsample1 = BasicConv2d(channel, channel, 3, padding=1)\n        # self.conv_upsample2 = BasicConv2d(channel, channel, 3, padding=1)\n        # self.conv_upsample3 = BasicConv2d(channel, channel, 3, padding=1)\n        # self.conv_upsample4 = BasicConv2d(channel, channel, 3, padding=1)\n        # self.conv_upsample5 = BasicConv2d(2*channel, 2*channel, 3, padding=1)",
        "detail": "network.Ablation_model",
        "documentation": {}
    },
    {
        "label": "SemiModel_without_agg_init",
        "kind": 6,
        "importPath": "network.Ablation_model",
        "description": "network.Ablation_model",
        "peekOfCode": "class SemiModel_without_agg_init(nn.Module):\n    def __init__(self, channel=32):\n        super(SemiModel_without_agg_init, self).__init__()\n        vgg16_bn = models.vgg16_bn(pretrained=True)\n        self.inc = vgg16_bn.features[:5]  # 64\n        self.down1 = vgg16_bn.features[5:12]  # 128\n        self.down2 = vgg16_bn.features[12:22]  # 256\n        self.down3 = vgg16_bn.features[22:32]  # 512\n        self.down4 = vgg16_bn.features[32:42]  # 512\n        self.rfb3 = GCM(256, channel)",
        "detail": "network.Ablation_model",
        "documentation": {}
    },
    {
        "label": "replace_aggregation_final",
        "kind": 6,
        "importPath": "network.Ablation_model",
        "description": "network.Ablation_model",
        "peekOfCode": "class replace_aggregation_final(nn.Module):\n    def __init__(self, channel):\n        super(replace_aggregation_final, self).__init__()\n        self.relu = nn.ReLU(True)\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        # self.conv_upsample1 = BasicConv2d(channel, channel, 3, padding=1)\n        # self.conv_upsample2 = BasicConv2d(channel, channel, 3, padding=1)\n        # self.conv_upsample3 = BasicConv2d(channel, channel, 3, padding=1)\n        # self.conv_upsample4 = BasicConv2d(channel, channel, 3, padding=1)\n        # self.conv_upsample5 = BasicConv2d(2*channel, 2*channel, 3, padding=1)",
        "detail": "network.Ablation_model",
        "documentation": {}
    },
    {
        "label": "SemiModel_without_agg_final",
        "kind": 6,
        "importPath": "network.Ablation_model",
        "description": "network.Ablation_model",
        "peekOfCode": "class SemiModel_without_agg_final(nn.Module):\n    def __init__(self, channel=32):\n        super(SemiModel_without_agg_final, self).__init__()\n        vgg16_bn = models.vgg16_bn(pretrained=True)\n        self.inc = vgg16_bn.features[:5]  # 64\n        self.down1 = vgg16_bn.features[5:12]  # 128\n        self.down2 = vgg16_bn.features[12:22]  # 256\n        self.down3 = vgg16_bn.features[22:32]  # 512\n        self.down4 = vgg16_bn.features[32:42]  # 512\n        self.rfb3 = GCM(256, channel)",
        "detail": "network.Ablation_model",
        "documentation": {}
    },
    {
        "label": "TransBasicBlock",
        "kind": 6,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "class TransBasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, upsample=None, **kwargs):\n        super(TransBasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, inplanes)\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        if upsample is not None and stride != 1:\n            self.conv2 = nn.ConvTranspose2d(inplanes, planes,\n                                            kernel_size=3, stride=stride, padding=1,",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "ChannelAttention",
        "kind": 6,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "class ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n        self.relu1 = nn.ReLU()\n        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, x):\n        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SpatialAttention",
        "kind": 6,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "class SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        padding = 3 if kernel_size == 7 else 1\n        self.conv1 = nn.Conv2d(1, 1, kernel_size, padding=padding, bias=False)\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, x):\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x=max_out\n        x = self.conv1(x)",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "BasicConv2d",
        "kind": 6,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "class BasicConv2d(nn.Module):\n    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes,\n                              kernel_size=kernel_size, stride=stride,\n                              padding=padding, dilation=dilation, bias=False)\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x = self.conv(x)",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "GCM",
        "kind": 6,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "class GCM(nn.Module):\n    def __init__(self, in_channel, out_channel):\n        super(GCM, self).__init__()\n        self.relu = nn.ReLU(True)\n        self.branch0 = nn.Sequential(\n            BasicConv2d(in_channel, out_channel, 1),\n        )\n        self.branch1 = nn.Sequential(\n            BasicConv2d(in_channel, out_channel, 1),\n            BasicConv2d(out_channel, out_channel, kernel_size=(1, 3), padding=(0, 1)),",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "aggregation_init",
        "kind": 6,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "class aggregation_init(nn.Module):\n    def __init__(self, channel):\n        super(aggregation_init, self).__init__()\n        self.relu = nn.ReLU(True)\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.conv_upsample1 = BasicConv2d(channel, channel, 3, padding=1)\n        self.conv_upsample2 = BasicConv2d(channel, channel, 3, padding=1)\n        self.conv_upsample3 = BasicConv2d(channel, channel, 3, padding=1)\n        self.conv_upsample4 = BasicConv2d(channel, channel, 3, padding=1)\n        self.conv_upsample5 = BasicConv2d(2*channel, 2*channel, 3, padding=1)",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "aggregation_final",
        "kind": 6,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "class aggregation_final(nn.Module):\n    def __init__(self, channel):\n        super(aggregation_final, self).__init__()\n        self.relu = nn.ReLU(True)\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.conv_upsample1 = BasicConv2d(channel, channel, 3, padding=1)\n        self.conv_upsample2 = BasicConv2d(channel, channel, 3, padding=1)\n        self.conv_upsample3 = BasicConv2d(channel, channel, 3, padding=1)\n        self.conv_upsample4 = BasicConv2d(channel, channel, 3, padding=1)\n        self.conv_upsample5 = BasicConv2d(2*channel, 2*channel, 3, padding=1)",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "Refine",
        "kind": 6,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "class Refine(nn.Module):\n    def __init__(self):\n        super(Refine,self).__init__()\n        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.upsample4 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n    def forward(self, attention,x1,x2,x3):\n        x1 = x1+torch.mul(x1, self.upsample4(attention))\n        x2 = x2+torch.mul(x2,self.upsample2(attention))\n        x3 = x3+torch.mul(x3,attention)\n        return x1,x2,x3",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel",
        "kind": 6,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "class SemiModel(nn.Module):\n    def __init__(self, channel=32):\n        super(SemiModel, self).__init__()\n        vgg16_bn = models.vgg16_bn(pretrained=True)\n        self.inc = vgg16_bn.features[:5]  # 64\n        self.down1 = vgg16_bn.features[5:12]  # 128\n        self.down2 = vgg16_bn.features[12:22]  # 256\n        self.down3 = vgg16_bn.features[22:32]  # 512\n        self.down4 = vgg16_bn.features[32:42]  # 512\n        self.rfb3 = GCM(256, channel)",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "SemiModel_visualization",
        "kind": 6,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "class SemiModel_visualization(nn.Module):\n    def __init__(self, channel=32):\n        super(SemiModel_visualization, self).__init__()\n        vgg16_bn = models.vgg16_bn(pretrained=True)\n        self.inc = vgg16_bn.features[:5]  # 64\n        self.down1 = vgg16_bn.features[5:12]  # 128\n        self.down2 = vgg16_bn.features[12:22]  # 256\n        self.down3 = vgg16_bn.features[22:32]  # 512\n        self.down4 = vgg16_bn.features[32:42]  # 512\n        self.rfb3 = GCM(256, channel)",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "conv3x3",
        "kind": 2,
        "importPath": "network.SemiModel",
        "description": "network.SemiModel",
        "peekOfCode": "def conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\nclass TransBasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, inplanes, planes, stride=1, upsample=None, **kwargs):\n        super(TransBasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, inplanes)\n        self.bn1 = nn.BatchNorm2d(inplanes)",
        "detail": "network.SemiModel",
        "documentation": {}
    },
    {
        "label": "ChangeDataset",
        "kind": 6,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "class ChangeDataset(data.Dataset):\n    def __init__(self, root, trainsize, mosaic_ratio=0.75):\n        self.trainsize = trainsize\n        # get filenames\n        self.image_root_A =  root + 'A/'\n        self.image_root_B =  root + 'B/'\n        self.gt_root = root + 'label/'\n        self.mosaic_ratio = mosaic_ratio\n        self.images_A = [self.image_root_A + f for f in os.listdir(self.image_root_A) if f.endswith('.jpg') or f.endswith('.png')]\n        self.images_B = [self.image_root_B + f for f in os.listdir(self.image_root_B) if f.endswith('.jpg') or f.endswith('.png')]",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "Test_ChangeDataset",
        "kind": 6,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "class Test_ChangeDataset(data.Dataset):\n    def __init__(self, root, trainsize):\n        self.trainsize = trainsize\n        # get filenames\n        image_root_A =  root + 'A/'\n        image_root_B =  root + 'B/'\n        gt_root = root + 'label/'\n        self.images_A = [image_root_A + f for f in os.listdir(image_root_A) if f.endswith('.jpg') or f.endswith('.png')]\n        self.images_B = [image_root_B + f for f in os.listdir(image_root_B) if f.endswith('.jpg') or f.endswith('.png')]\n        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg')",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "SemiChangeDataset",
        "kind": 6,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "class SemiChangeDataset(data.Dataset):\n    def __init__(self, root, trainsize, train_ratio=1,mosaic_ratio=0.75):\n        self.trainsize = trainsize\n        # get filenames\n        self.image_root_A =  root + 'A/'\n        self.image_root_B =  root + 'B/'\n        self.gt_root = root + 'label/'\n        assert train_ratio<=1 and train_ratio>=0\n        self.train_ratio = train_ratio\n        self.mosaic_ratio = mosaic_ratio",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "cv_random_flip",
        "kind": 2,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "def cv_random_flip(img_A, img_B, label):\n    # left right flip\n    flip_flag = random.randint(0, 1)\n    if flip_flag == 1:\n        img_A = img_A.transpose(Image.FLIP_LEFT_RIGHT)\n        img_B = img_B.transpose(Image.FLIP_LEFT_RIGHT)\n        label = label.transpose(Image.FLIP_LEFT_RIGHT)\n    return img_A, img_B, label\ndef randomCrop_Mosaic(image_A, image_B, label, crop_win_width, crop_win_height):\n    image_width = image_A.size[0]",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "randomCrop_Mosaic",
        "kind": 2,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "def randomCrop_Mosaic(image_A, image_B, label, crop_win_width, crop_win_height):\n    image_width = image_A.size[0]\n    image_height = image_A.size[1]\n    random_region = (\n        (image_width - crop_win_width) >> 1, (image_height - crop_win_height) >> 1, (image_width + crop_win_width) >> 1,\n        (image_height + crop_win_height) >> 1)\n    return image_A.crop(random_region), image_B.crop(random_region), label.crop(random_region)\ndef randomCrop(image_A, image_B, label):\n    border = 30\n    image_width = image_A.size[0]",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "randomCrop",
        "kind": 2,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "def randomCrop(image_A, image_B, label):\n    border = 30\n    image_width = image_A.size[0]\n    image_height = image_B.size[1]\n    crop_win_width = np.random.randint(image_width - border, image_width)\n    crop_win_height = np.random.randint(image_height - border, image_height)\n    random_region = (\n        (image_width - crop_win_width) >> 1, (image_height - crop_win_height) >> 1, (image_width + crop_win_width) >> 1,\n        (image_height + crop_win_height) >> 1)\n    return image_A.crop(random_region), image_B.crop(random_region), label.crop(random_region)",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "randomRotation",
        "kind": 2,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "def randomRotation(image_A, image_B, label):\n    mode = Image.BICUBIC\n    if random.random() > 0.8:\n        random_angle = np.random.randint(-15, 15)\n        image_A = image_A.rotate(random_angle, mode)\n        image_B = image_B.rotate(random_angle, mode)\n        label = label.rotate(random_angle, mode)\n    return image_A, image_B, label\ndef colorEnhance(image_A, image_B):\n    bright_intensity = random.randint(5, 15) / 10.0",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "colorEnhance",
        "kind": 2,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "def colorEnhance(image_A, image_B):\n    bright_intensity = random.randint(5, 15) / 10.0\n    image_A = ImageEnhance.Brightness(image_A).enhance(bright_intensity)\n    image_B = ImageEnhance.Brightness(image_B).enhance(bright_intensity)\n    contrast_intensity = random.randint(5, 15) / 10.0\n    image_A = ImageEnhance.Contrast(image_A).enhance(contrast_intensity)\n    image_B = ImageEnhance.Contrast(image_B).enhance(contrast_intensity)\n    color_intensity = random.randint(0, 20) / 10.0\n    image_A = ImageEnhance.Color(image_A).enhance(color_intensity)\n    image_B = ImageEnhance.Color(image_B).enhance(color_intensity)",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "randomGaussian",
        "kind": 2,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "def randomGaussian(image, mean=0.1, sigma=0.35):\n    def gaussianNoisy(im, mean=mean, sigma=sigma):\n        for _i in range(len(im)):\n            im[_i] += random.gauss(mean, sigma)\n        return im\n    img = np.asarray(image)\n    width, height = img.shape\n    img = gaussianNoisy(img[:].flatten(), mean, sigma)\n    img = img.reshape([width, height])\n    return Image.fromarray(np.uint8(img))",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "randomPeper",
        "kind": 2,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "def randomPeper(img):\n    img = np.array(img)\n    noiseNum = int(0.0015 * img.shape[0] * img.shape[1])\n    for i in range(noiseNum):\n        randX = random.randint(0, img.shape[0] - 1)\n        randY = random.randint(0, img.shape[1] - 1)\n        if random.randint(0, 1) == 0:\n            img[randX, randY] = 0\n        else:\n            img[randX, randY] = 255",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "get_loader",
        "kind": 2,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "def get_loader(root, batchsize, trainsize, num_workers=1, shuffle=True, pin_memory=True):\n    dataset =ChangeDataset(root = root, trainsize= trainsize)\n    data_loader = data.DataLoader(dataset=dataset,\n                                  batch_size=batchsize,\n                                  shuffle=shuffle,\n                                  num_workers=num_workers,\n                                  pin_memory=pin_memory)\n    return data_loader\ndef get_test_loader(root, batchsize, trainsize, num_workers=1, shuffle=True, pin_memory=True):\n    dataset =Test_ChangeDataset(root = root, trainsize= trainsize)",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "get_test_loader",
        "kind": 2,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "def get_test_loader(root, batchsize, trainsize, num_workers=1, shuffle=True, pin_memory=True):\n    dataset =Test_ChangeDataset(root = root, trainsize= trainsize)\n    data_loader = data.DataLoader(dataset=dataset,\n                                  batch_size=batchsize,\n                                  shuffle=shuffle,\n                                  num_workers=num_workers,\n                                  pin_memory=pin_memory)\n    return data_loader\nclass SemiChangeDataset(data.Dataset):\n    def __init__(self, root, trainsize, train_ratio=1,mosaic_ratio=0.75):",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "get_semiloader",
        "kind": 2,
        "importPath": "utils.data_loader",
        "description": "utils.data_loader",
        "peekOfCode": "def get_semiloader(root, batchsize, trainsize,train_ratio, num_workers=1, shuffle=True, pin_memory=True):\n    dataset =SemiChangeDataset(root = root, trainsize= trainsize,train_ratio=train_ratio)\n    data_loader = data.DataLoader(dataset=dataset,\n                                  batch_size=batchsize,\n                                  shuffle=shuffle,\n                                  num_workers=num_workers,\n                                  pin_memory=pin_memory)\n    return data_loader",
        "detail": "utils.data_loader",
        "documentation": {}
    },
    {
        "label": "PairedChangeDataset",
        "kind": 6,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "class PairedChangeDataset(data.Dataset):\n    def __init__(self, csv_path, trainsize, mosaic_ratio=0.75):\n        df = pd.read_csv(csv_path)\n        # Check column names and adapt to what's available in the CSV\n        if 'past_image_path' in df.columns and 'present_image_path' in df.columns:\n            self.past_paths = df['past_image_path'].tolist()\n            self.present_paths = df['present_image_path'].tolist()\n            if 'mask_path' in df.columns:\n                self.mask_paths = df['mask_path'].tolist()\n            else:",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "UnpairedChangeDataset",
        "kind": 6,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "class UnpairedChangeDataset(data.Dataset):\n    def __init__(self, csv_path, trainsize):\n        df = pd.read_csv(csv_path)\n        # Check column names and adapt to what's available in the CSV\n        if 'past_image_path' in df.columns and 'present_image_path' in df.columns:\n            self.past_paths = df['past_image_path'].tolist()\n            self.present_paths = df['present_image_path'].tolist()\n        else:\n            # Fallback to original column names\n            self.past_paths = df['past'].tolist()",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "cv_random_flip",
        "kind": 2,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "def cv_random_flip(img_A, img_B, label):\n    if random.random() > 0.5:\n        img_A = img_A.transpose(Image.FLIP_LEFT_RIGHT)\n        img_B = img_B.transpose(Image.FLIP_LEFT_RIGHT)\n        label = label.transpose(Image.FLIP_LEFT_RIGHT)\n    return img_A, img_B, label\ndef randomCrop(image_A, image_B, label, border=30):\n    w, h = image_A.size\n    cw = np.random.randint(w - border, w)\n    ch = np.random.randint(h - border, h)",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "randomCrop",
        "kind": 2,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "def randomCrop(image_A, image_B, label, border=30):\n    w, h = image_A.size\n    cw = np.random.randint(w - border, w)\n    ch = np.random.randint(h - border, h)\n    region = ((w - cw)//2, (h - ch)//2, (w + cw)//2, (h + ch)//2)\n    return image_A.crop(region), image_B.crop(region), label.crop(region)\ndef randomRotation(image_A, image_B, label, angle_range=15):\n    if random.random() > 0.8:\n        ang = random.randint(-angle_range, angle_range)\n        image_A = image_A.rotate(ang, Image.BICUBIC)",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "randomRotation",
        "kind": 2,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "def randomRotation(image_A, image_B, label, angle_range=15):\n    if random.random() > 0.8:\n        ang = random.randint(-angle_range, angle_range)\n        image_A = image_A.rotate(ang, Image.BICUBIC)\n        image_B = image_B.rotate(ang, Image.BICUBIC)\n        label   = label.rotate(ang, Image.NEAREST)\n    return image_A, image_B, label\ndef colorEnhance(image_A, image_B):\n    for fn in (ImageEnhance.Brightness, ImageEnhance.Contrast,\n               ImageEnhance.Color, ImageEnhance.Sharpness):",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "colorEnhance",
        "kind": 2,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "def colorEnhance(image_A, image_B):\n    for fn in (ImageEnhance.Brightness, ImageEnhance.Contrast,\n               ImageEnhance.Color, ImageEnhance.Sharpness):\n        factor = random.uniform(0.5, 1.5)\n        image_A = fn(image_A).enhance(factor)\n        image_B = fn(image_B).enhance(factor)\n    return image_A, image_B\ndef randomPeper(img):\n    arr = np.array(img)\n    n = int(0.0015 * arr.size)",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "randomPeper",
        "kind": 2,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "def randomPeper(img):\n    arr = np.array(img)\n    n = int(0.0015 * arr.size)\n    for _ in range(n):\n        x = random.randrange(arr.shape[0])\n        y = random.randrange(arr.shape[1])\n        arr[x, y] = 0 if random.random()<0.5 else 255\n    return Image.fromarray(arr)\n# ─── helper to load a .tif into a PIL image ────────────────────────────────\ndef load_tif_rgb(path, bands=[4,3,2]):",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "load_tif_rgb",
        "kind": 2,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "def load_tif_rgb(path, bands=[4,3,2]):\n    \"\"\"Read bands [4,3,2] from a GeoTIFF, replace NaNs, return as PIL RGB.\"\"\"\n    with rasterio.open(path) as src:\n        arr = src.read(bands).astype(np.float32)\n        arr = np.nan_to_num(arr, nan=0.0)\n    # transpose to HWC and clip/scale if you wish; here we normalize to [0,1]\n    arr = np.clip(arr, 0, None)\n    arr = arr / (arr.max() or 1)\n    arr = np.transpose(arr, (1, 2, 0))\n    # convert to 0–255 uint8 for PIL",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "load_tif_gray",
        "kind": 2,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "def load_tif_gray(path):\n    \"\"\"Read first band of a mask-tif, replace NaNs, return as PIL L.\"\"\"\n    with rasterio.open(path) as src:\n        arr = src.read(1).astype(np.float32)\n        arr = np.nan_to_num(arr, nan=0.0)\n    # assume mask is binary or 0–1; scale up\n    arr = np.clip(arr, 0, 1)\n    img8 = (arr * 255).round().astype(np.uint8)\n    return Image.fromarray(img8, mode='L')\n# ─── Paired (labelled) dataset ─────────────────────────────────────────────",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "get_paired_loader",
        "kind": 2,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "def get_paired_loader(csv_path, batchsize, trainsize,\n                      mosaic_ratio=0.75,\n                      num_workers=4, shuffle=True, pin_memory=True):\n    ds = PairedChangeDataset(csv_path, trainsize, mosaic_ratio)\n    return data.DataLoader(ds, batch_size=batchsize, shuffle=shuffle,\n                           num_workers=num_workers, pin_memory=pin_memory)\ndef get_unpaired_loader(csv_path, batchsize, trainsize,\n                        num_workers=4, shuffle=True, pin_memory=True):\n    ds = UnpairedChangeDataset(csv_path, trainsize)\n    return data.DataLoader(ds, batch_size=batchsize, shuffle=shuffle,",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "get_unpaired_loader",
        "kind": 2,
        "importPath": "utils.data_loader_tif",
        "description": "utils.data_loader_tif",
        "peekOfCode": "def get_unpaired_loader(csv_path, batchsize, trainsize,\n                        num_workers=4, shuffle=True, pin_memory=True):\n    ds = UnpairedChangeDataset(csv_path, trainsize)\n    return data.DataLoader(ds, batch_size=batchsize, shuffle=shuffle,\n                           num_workers=num_workers, pin_memory=pin_memory)",
        "detail": "utils.data_loader_tif",
        "documentation": {}
    },
    {
        "label": "dice_bce_loss",
        "kind": 6,
        "importPath": "utils.loss",
        "description": "utils.loss",
        "peekOfCode": "class dice_bce_loss(nn.Module):\n    def __init__(self, batch=True):\n        super(dice_bce_loss, self).__init__()\n        self.batch = batch\n        self.bce_loss = nn.BCELoss()\n    def soft_dice_coeff(self, y_true, y_pred):\n        smooth = 0.0  # may change\n        if self.batch:\n            i = torch.sum(y_true)\n            j = torch.sum(y_pred)",
        "detail": "utils.loss",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "kind": 6,
        "importPath": "utils.metrics",
        "description": "utils.metrics",
        "peekOfCode": "class Evaluator(object):\n    def __init__(self, num_class):\n        self.num_class = num_class\n        self.confusion_matrix = np.zeros((self.num_class,)*2)\n    def get_tp_fp_tn_fn(self):\n        tp = np.diag(self.confusion_matrix)\n        fp = self.confusion_matrix.sum(axis=0) - np.diag(self.confusion_matrix)\n        fn = self.confusion_matrix.sum(axis=1) - np.diag(self.confusion_matrix)\n        tn = np.diag(self.confusion_matrix).sum() - np.diag(self.confusion_matrix)\n        return tp, fp, tn, fn",
        "detail": "utils.metrics",
        "documentation": {}
    },
    {
        "label": "AvgMeter",
        "kind": 6,
        "importPath": "utils.utils",
        "description": "utils.utils",
        "peekOfCode": "class AvgMeter(object):\n    def __init__(self, num=40):\n        self.num = num\n        self.reset()\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n        self.losses = []",
        "detail": "utils.utils",
        "documentation": {}
    },
    {
        "label": "clip_gradient",
        "kind": 2,
        "importPath": "utils.utils",
        "description": "utils.utils",
        "peekOfCode": "def clip_gradient(optimizer, grad_clip):\n    \"\"\"\n    For calibrating misalignment gradient via cliping gradient technique\n    :param optimizer:\n    :param grad_clip:\n    :return:\n    \"\"\"\n    for group in optimizer.param_groups:\n        for param in group['params']:\n            if param.grad is not None:",
        "detail": "utils.utils",
        "documentation": {}
    },
    {
        "label": "adjust_lr",
        "kind": 2,
        "importPath": "utils.utils",
        "description": "utils.utils",
        "peekOfCode": "def adjust_lr(optimizer, init_lr, epoch, decay_rate=0.1, decay_epoch=30):\n    decay = decay_rate ** (epoch // decay_epoch)\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = decay*init_lr\n        lr=param_group['lr']\n    return lr\n# def adjust_lr(optimizer, init_lr, epoch, decay_rate=0.1, decay_epoch=30):\n#     decay = decay_rate ** (epoch // decay_epoch)\n#     for param_group in optimizer.param_groups:\n#         param_group['lr'] *= decay",
        "detail": "utils.utils",
        "documentation": {}
    },
    {
        "label": "CalParams",
        "kind": 2,
        "importPath": "utils.utils",
        "description": "utils.utils",
        "peekOfCode": "def CalParams(model, input_tensor):\n    \"\"\"\n    Usage:\n        Calculate Params and FLOPs via [THOP](https://github.com/Lyken17/pytorch-OpCounter)\n    Necessarity:\n        from thop import profile\n        from thop import clever_format\n    :param model:\n    :param input_tensor:\n    :return:",
        "detail": "utils.utils",
        "documentation": {}
    },
    {
        "label": "Visualization",
        "kind": 6,
        "importPath": "utils.visualization",
        "description": "utils.visualization",
        "peekOfCode": "class Visualization:\n    def __init__(self):\n        self.writer = ''#= SummaryWriter(logdir=model_type, comment=model_type)\n    def create_summary(self, model_type='U_Net'):\n        \"\"\"新建writer 设置路径\"\"\"\n        # self.writer = SummaryWriter(model_type, comment=model_type)\n        self.writer = SummaryWriter(comment='-' +model_type)\n    def add_scalar(self, epoch, value, params='loss'):\n        \"\"\"添加训练记录\"\"\"\n        self.writer.add_scalar(params, value, global_step=epoch)",
        "detail": "utils.visualization",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "create_labelled_dataset",
        "description": "create_labelled_dataset",
        "peekOfCode": "def main():\n    # Root folder containing your subfolders\n    root_dir = Path(__file__).parent / \"dataset_delhi\"\n    # Define subdirectories\n    mask_dir = root_dir / \"mask\"\n    data_dirs = {\n        \"2018\": root_dir / \"2018_data\",\n        \"2019\": root_dir / \"2019_data\",\n        \"2020\": root_dir / \"2020_data\",\n        \"2023\": root_dir / \"2023_data\",",
        "detail": "create_labelled_dataset",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "create_unlabelled_dataset",
        "description": "create_unlabelled_dataset",
        "peekOfCode": "def main():\n    root = Path(__file__).parent / \"dataset_delhi\"\n    paired_csv = root / \"paired_dataset.csv\"\n    out_csv    = root / \"unpaired_pairs.csv\"\n    # 1) Read mask-paired CSV and collect used IDs per year\n    #    We infer each row: mask covers (Y1,Y2) and past_image_path ends in _XX_YY.tif\n    used_ids = {(\"2018\",\"2020\"): set(), (\"2019\",\"2023\"): set()}\n    with paired_csv.open() as f:\n        reader = csv.DictReader(f)\n        for row in reader:",
        "detail": "create_unlabelled_dataset",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "create_validation_dataset",
        "description": "create_validation_dataset",
        "peekOfCode": "def main():\n    # Root folder containing your subfolders\n    root_dir = Path(__file__).parent / \"dataset_delhi\"\n    # Input paired dataset CSV\n    paired_csv = root_dir / \"paired_dataset.csv\"\n    # Output validation dataset CSV\n    val_csv = root_dir / \"val_dataset.csv\"\n    # Validation split ratio (e.g., 20% of paired data for validation)\n    val_ratio = 0.2\n    # Read all paired data",
        "detail": "create_validation_dataset",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "test_Ablation",
        "description": "test_Ablation",
        "peekOfCode": "def test(test_loader, Eva_test, save_path, net):\n    print(\"Strat validing!\")\n    net.train(False)\n    net.eval()\n    for i, (A, B, mask, filename) in enumerate(tqdm(test_loader)):\n        with torch.no_grad():\n            A = A.cuda()\n            B = B.cuda()\n            Y = mask.cuda()\n            preds = net(A,B)",
        "detail": "test_Ablation",
        "documentation": {}
    },
    {
        "label": "#os.environ['CUDA_VISIBLE_DEVICES']",
        "kind": 5,
        "importPath": "test_Ablation",
        "description": "test_Ablation",
        "peekOfCode": "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom utils import data_loader\nfrom tqdm import tqdm\nfrom utils.metrics import Evaluator\n# from network.Net import HANet_v2\nfrom PIL import Image\nfrom network.Net2 import HANet_v2,HANet_v3,HANet_v4",
        "detail": "test_Ablation",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "test_C2F-SemiCD",
        "description": "test_C2F-SemiCD",
        "peekOfCode": "def test(test_loader, Eva_test, save_path, net):\n    print(\"Strat validing!\")\n    net.train(False)\n    net.eval()\n    for i, (A, B, mask, filename) in enumerate(tqdm(test_loader)):\n        with torch.no_grad():\n            A = A.cuda()\n            B = B.cuda()\n            Y = mask.cuda()\n            preds = net(A,B)",
        "detail": "test_C2F-SemiCD",
        "documentation": {}
    },
    {
        "label": "#os.environ['CUDA_VISIBLE_DEVICES']",
        "kind": 5,
        "importPath": "test_C2F-SemiCD",
        "description": "test_C2F-SemiCD",
        "peekOfCode": "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom utils import data_loader\nfrom tqdm import tqdm\nfrom utils.metrics import Evaluator\nfrom PIL import Image\nfrom network.SemiModel import SemiModel\nimport time",
        "detail": "test_C2F-SemiCD",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "test_C2FNet",
        "description": "test_C2FNet",
        "peekOfCode": "def test(test_loader, Eva_test, save_path, net):\n    print(\"Strat validing!\")\n    net.train(False)\n    net.eval()\n    for i, (A, B, mask, filename) in enumerate(tqdm(test_loader)):\n        with torch.no_grad():\n            A = A.cuda()\n            B = B.cuda()\n            Y = mask.cuda()\n            preds = net(A,B)",
        "detail": "test_C2FNet",
        "documentation": {}
    },
    {
        "label": "#os.environ['CUDA_VISIBLE_DEVICES']",
        "kind": 5,
        "importPath": "test_C2FNet",
        "description": "test_C2FNet",
        "peekOfCode": "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom utils import data_loader\nfrom tqdm import tqdm\nfrom utils.metrics import Evaluator\nfrom PIL import Image\nfrom network.SemiModel import SemiModel\nimport time",
        "detail": "test_C2FNet",
        "documentation": {}
    },
    {
        "label": "test_visualization",
        "kind": 2,
        "importPath": "test_Visualization",
        "description": "test_Visualization",
        "peekOfCode": "def test_visualization(test_loader, Eva_test, save_path, net):\n    print(\"Strat validing!\")\n   # net: SemiModel_visualization\n    net.train(False)\n    net.eval()\n    for i, (A, B, mask, filename) in enumerate(tqdm(test_loader)):\n        with torch.no_grad():\n            A = A.cuda()\n            B = B.cuda()\n            Y = mask.cuda()",
        "detail": "test_Visualization",
        "documentation": {}
    },
    {
        "label": "#os.environ['CUDA_VISIBLE_DEVICES']",
        "kind": 5,
        "importPath": "test_Visualization",
        "description": "test_Visualization",
        "peekOfCode": "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom utils import data_loader\nfrom tqdm import tqdm\nfrom utils.metrics import Evaluator\n# from network.Net import HANet_v2\nfrom PIL import Image\nfrom network.Net2 import HANet_v2,HANet_v3,HANet_v4",
        "detail": "test_Visualization",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "kind": 2,
        "importPath": "train_C2F-SemiCD",
        "description": "train_C2F-SemiCD",
        "peekOfCode": "def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\ndef update_ema_variables(model, ema_model, alpha):  #alpha是啥意思\n    model_state = model.state_dict()",
        "detail": "train_C2F-SemiCD",
        "documentation": {}
    },
    {
        "label": "update_ema_variables",
        "kind": 2,
        "importPath": "train_C2F-SemiCD",
        "description": "train_C2F-SemiCD",
        "peekOfCode": "def update_ema_variables(model, ema_model, alpha):  #alpha是啥意思\n    model_state = model.state_dict()\n    model_ema_state = ema_model.state_dict()\n    new_dict = {}\n    for key in model_state:\n        new_dict[key] = alpha * model_ema_state[key] + (1 - alpha) * model_state[key]\n    ema_model.load_state_dict(new_dict)\ndef train1(train_loader, val_loader, Eva_train,Eva_train2, Eva_val,Eva_val2,\n           data_name, save_path, net,ema_net, criterion,semicriterion, optimizer,use_ema, num_epoches):\n    vis = visual.Visualization()",
        "detail": "train_C2F-SemiCD",
        "documentation": {}
    },
    {
        "label": "train1",
        "kind": 2,
        "importPath": "train_C2F-SemiCD",
        "description": "train_C2F-SemiCD",
        "peekOfCode": "def train1(train_loader, val_loader, Eva_train,Eva_train2, Eva_val,Eva_val2,\n           data_name, save_path, net,ema_net, criterion,semicriterion, optimizer,use_ema, num_epoches):\n    vis = visual.Visualization()\n    vis.create_summary(data_name)\n    global best_iou\n    epoch_loss = 0\n    net.train(True)\n    ema_net.train(True)\n    length = 0\n    st = time.time()",
        "detail": "train_C2F-SemiCD",
        "documentation": {}
    },
    {
        "label": "#os.environ['CUDA_VISIBLE_DEVICES']",
        "kind": 5,
        "importPath": "train_C2F-SemiCD",
        "description": "train_C2F-SemiCD",
        "peekOfCode": "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\nimport torch\nimport torch.nn.functional as F\n#from catalyst.contrib.nn import Lookahead\nimport torch.nn as nn\nimport numpy as np\nimport utils.visualization as visual\nfrom utils import data_loader\nfrom tqdm import tqdm\nimport random",
        "detail": "train_C2F-SemiCD",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "kind": 2,
        "importPath": "train_C2F-SemiCD2",
        "description": "train_C2F-SemiCD2",
        "peekOfCode": "def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\ndef update_ema_variables(model, ema_model, alpha):  #alpha是啥意思\n    model_state = model.state_dict()",
        "detail": "train_C2F-SemiCD2",
        "documentation": {}
    },
    {
        "label": "update_ema_variables",
        "kind": 2,
        "importPath": "train_C2F-SemiCD2",
        "description": "train_C2F-SemiCD2",
        "peekOfCode": "def update_ema_variables(model, ema_model, alpha):  #alpha是啥意思\n    model_state = model.state_dict()\n    model_ema_state = ema_model.state_dict()\n    new_dict = {}\n    for key in model_state:\n        new_dict[key] = alpha * model_ema_state[key] + (1 - alpha) * model_state[key]\n    ema_model.load_state_dict(new_dict)\ndef train(train_loader, val_loader, Eva_train,Eva_train2, Eva_val,Eva_val2, data_name, save_path, net,ema_net, criterion,semicriterion, optimizer,use_ema, num_epoches):\n    vis = visual.Visualization()\n    vis.create_summary(data_name)",
        "detail": "train_C2F-SemiCD2",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "train_C2F-SemiCD2",
        "description": "train_C2F-SemiCD2",
        "peekOfCode": "def train(train_loader, val_loader, Eva_train,Eva_train2, Eva_val,Eva_val2, data_name, save_path, net,ema_net, criterion,semicriterion, optimizer,use_ema, num_epoches):\n    vis = visual.Visualization()\n    vis.create_summary(data_name)\n    global best_iou\n    epoch_loss = 0\n    net.train(True)\n    ema_net.train(True)\n    length = 0\n    st = time.time()\n    loss_semi=torch.zeros(1)",
        "detail": "train_C2F-SemiCD2",
        "documentation": {}
    },
    {
        "label": "train1",
        "kind": 2,
        "importPath": "train_C2F-SemiCD2",
        "description": "train_C2F-SemiCD2",
        "peekOfCode": "def train1(train_loader, val_loader, Eva_train,Eva_train2, Eva_val,Eva_val2,\n           data_name, save_path, net,ema_net, criterion,semicriterion, optimizer,use_ema, num_epoches):\n    vis = visual.Visualization()\n    vis.create_summary(data_name)\n    global best_iou\n    epoch_loss = 0\n    net.train(True)\n    ema_net.train(True)\n    length = 0\n    st = time.time()",
        "detail": "train_C2F-SemiCD2",
        "documentation": {}
    },
    {
        "label": "#os.environ['CUDA_VISIBLE_DEVICES']",
        "kind": 5,
        "importPath": "train_C2F-SemiCD2",
        "description": "train_C2F-SemiCD2",
        "peekOfCode": "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\nimport torch\nimport torch.nn.functional as F\n#from catalyst.contrib.nn import Lookahead\nimport torch.nn as nn\nimport numpy as np\nimport utils.visualization as visual\nfrom utils import data_loader\nfrom tqdm import tqdm\nimport random",
        "detail": "train_C2F-SemiCD2",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "kind": 2,
        "importPath": "train_C2F-SemiCD_Ablation",
        "description": "train_C2F-SemiCD_Ablation",
        "peekOfCode": "def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\ndef update_ema_variables(model, ema_model, alpha):  # alpha是啥意思\n    model_state = model.state_dict()",
        "detail": "train_C2F-SemiCD_Ablation",
        "documentation": {}
    },
    {
        "label": "update_ema_variables",
        "kind": 2,
        "importPath": "train_C2F-SemiCD_Ablation",
        "description": "train_C2F-SemiCD_Ablation",
        "peekOfCode": "def update_ema_variables(model, ema_model, alpha):  # alpha是啥意思\n    model_state = model.state_dict()\n    model_ema_state = ema_model.state_dict()\n    new_dict = {}\n    for key in model_state:\n        new_dict[key] = alpha * model_ema_state[key] + (1 - alpha) * model_state[key]\n    ema_model.load_state_dict(new_dict)\ndef Ablation_train1(train_loader, val_loader, Eva_train, Eva_train2, Eva_val, Eva_val2,\n           data_name, save_path, net, ema_net, criterion, semicriterion, optimizer, use_ema, num_epoches):\n    vis = visual.Visualization()",
        "detail": "train_C2F-SemiCD_Ablation",
        "documentation": {}
    },
    {
        "label": "Ablation_train1",
        "kind": 2,
        "importPath": "train_C2F-SemiCD_Ablation",
        "description": "train_C2F-SemiCD_Ablation",
        "peekOfCode": "def Ablation_train1(train_loader, val_loader, Eva_train, Eva_train2, Eva_val, Eva_val2,\n           data_name, save_path, net, ema_net, criterion, semicriterion, optimizer, use_ema, num_epoches):\n    vis = visual.Visualization()\n    vis.create_summary(data_name)\n    global best_iou\n    epoch_loss = 0\n    net.train(True)\n    ema_net.train(True)\n    length = 0\n    st = time.time()",
        "detail": "train_C2F-SemiCD_Ablation",
        "documentation": {}
    },
    {
        "label": "start",
        "kind": 5,
        "importPath": "train_C2F-SemiCD_Ablation",
        "description": "train_C2F-SemiCD_Ablation",
        "peekOfCode": "start = time.time()\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\ndef update_ema_variables(model, ema_model, alpha):  # alpha是啥意思",
        "detail": "train_C2F-SemiCD_Ablation",
        "documentation": {}
    },
    {
        "label": "end",
        "kind": 5,
        "importPath": "train_C2F-SemiCD_Ablation",
        "description": "train_C2F-SemiCD_Ablation",
        "peekOfCode": "end = time.time()\nprint('程序训练train的时间为:', end - start)",
        "detail": "train_C2F-SemiCD_Ablation",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "kind": 2,
        "importPath": "train_C2F-SemiCD_tif",
        "description": "train_C2F-SemiCD_tif",
        "peekOfCode": "def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\ndef update_ema_variables(model, ema_model, alpha):\n    model_state = model.state_dict()",
        "detail": "train_C2F-SemiCD_tif",
        "documentation": {}
    },
    {
        "label": "update_ema_variables",
        "kind": 2,
        "importPath": "train_C2F-SemiCD_tif",
        "description": "train_C2F-SemiCD_tif",
        "peekOfCode": "def update_ema_variables(model, ema_model, alpha):\n    model_state = model.state_dict()\n    model_ema_state = ema_model.state_dict()\n    new_dict = {}\n    for key in model_state:\n        new_dict[key] = alpha * model_ema_state[key] + (1 - alpha) * model_state[key]\n    ema_model.load_state_dict(new_dict)\ndef train1(train_paired_loader, train_unpaired_loader, val_loader, Eva_train, Eva_train2, Eva_val, Eva_val2,\n           data_name, save_path, net, ema_net, criterion, semicriterion, optimizer, use_ema, num_epoches, epoch):\n    vis = visual.Visualization()",
        "detail": "train_C2F-SemiCD_tif",
        "documentation": {}
    },
    {
        "label": "train1",
        "kind": 2,
        "importPath": "train_C2F-SemiCD_tif",
        "description": "train_C2F-SemiCD_tif",
        "peekOfCode": "def train1(train_paired_loader, train_unpaired_loader, val_loader, Eva_train, Eva_train2, Eva_val, Eva_val2,\n           data_name, save_path, net, ema_net, criterion, semicriterion, optimizer, use_ema, num_epoches, epoch):\n    vis = visual.Visualization()\n    vis.create_summary(data_name)\n    global best_iou\n    epoch_loss = 0\n    net.train(True)\n    ema_net.train(True)\n    length = 0\n    st = time.time()",
        "detail": "train_C2F-SemiCD_tif",
        "documentation": {}
    },
    {
        "label": "seed_everything",
        "kind": 2,
        "importPath": "train_C2FNet",
        "description": "train_C2FNet",
        "peekOfCode": "def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\ndef update_ema_variables(model, ema_model, alpha):  #alpha是啥意思\n    model_state = model.state_dict()",
        "detail": "train_C2FNet",
        "documentation": {}
    },
    {
        "label": "update_ema_variables",
        "kind": 2,
        "importPath": "train_C2FNet",
        "description": "train_C2FNet",
        "peekOfCode": "def update_ema_variables(model, ema_model, alpha):  #alpha是啥意思\n    model_state = model.state_dict()\n    model_ema_state = ema_model.state_dict()\n    new_dict = {}\n    for key in model_state:\n        new_dict[key] = alpha * model_ema_state[key] + (1 - alpha) * model_state[key]\n    ema_model.load_state_dict(new_dict)\ndef train1(train_loader, val_loader, Eva_train,Eva_train2, Eva_val,Eva_val2,\n           data_name, save_path, net,ema_net, criterion,semicriterion, optimizer,use_ema, num_epoches):\n    vis = visual.Visualization()",
        "detail": "train_C2FNet",
        "documentation": {}
    },
    {
        "label": "train1",
        "kind": 2,
        "importPath": "train_C2FNet",
        "description": "train_C2FNet",
        "peekOfCode": "def train1(train_loader, val_loader, Eva_train,Eva_train2, Eva_val,Eva_val2,\n           data_name, save_path, net,ema_net, criterion,semicriterion, optimizer,use_ema, num_epoches):\n    vis = visual.Visualization()\n    vis.create_summary(data_name)\n    global best_iou\n    epoch_loss = 0\n    net.train(True)\n    ema_net.train(True)\n    length = 0\n    st = time.time()",
        "detail": "train_C2FNet",
        "documentation": {}
    },
    {
        "label": "#os.environ['CUDA_VISIBLE_DEVICES']",
        "kind": 5,
        "importPath": "train_C2FNet",
        "description": "train_C2FNet",
        "peekOfCode": "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\nimport torch\nimport torch.nn.functional as F\n#from catalyst.contrib.nn import Lookahead\nimport torch.nn as nn\nimport numpy as np\nimport utils.visualization as visual\nfrom utils import data_loader\nfrom tqdm import tqdm\nimport random",
        "detail": "train_C2FNet",
        "documentation": {}
    }
]